{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# COTS Detection Training code","metadata":{}},{"cell_type":"code","source":"# 安装所需的库\n# Install the required libraries\n!pip install -qU wandb\n!pip install -qU bbox-utility","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-15T13:19:52.455058Z","iopub.execute_input":"2022-04-15T13:19:52.455431Z","iopub.status.idle":"2022-04-15T13:20:16.197844Z","shell.execute_reply.started":"2022-04-15T13:19:52.455333Z","shell.execute_reply":"2022-04-15T13:20:16.196812Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport glob\nimport shutil\nimport sys\nfrom joblib import Parallel, delayed\nfrom IPython.display import display\n\nsys.path.append('../input/tensorflow-great-barrier-reef')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-15T13:20:16.199734Z","iopub.execute_input":"2022-04-15T13:20:16.200441Z","iopub.status.idle":"2022-04-15T13:20:16.706700Z","shell.execute_reply.started":"2022-04-15T13:20:16.200395Z","shell.execute_reply":"2022-04-15T13:20:16.706028Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# 登录 WANDB\n# login WANDB\nimport wandb\nwandb.login()","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:20:16.707912Z","iopub.execute_input":"2022-04-15T13:20:16.708651Z","iopub.status.idle":"2022-04-15T13:20:37.700656Z","shell.execute_reply.started":"2022-04-15T13:20:16.708610Z","shell.execute_reply":"2022-04-15T13:20:37.699676Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# 训练设置\n# Training\nFOLD      = 1  # 用来训练的FOLD  # which fold to train\nDIM       = 3000  # 输入尺寸  # Input size\nMODEL     = 'yolov5s6'  # 模型  # model\nBATCH     = 4\nEPOCHS    = 10\nOPTMIZER  = 'Adam'\n\nPROJECT   = 'great-barrier-reef-public' # w&b in yolov5\nNAME      = f'{MODEL}-dim{DIM}-fold{FOLD}' # w&b for yolov5\n\nREMOVE_NOBBOX = True  # 去除没有bbox的背景图片  # remove images with no bbox\nROOT_DIR  = '/kaggle/input/tensorflow-great-barrier-reef/'\nIMAGE_DIR = '/kaggle/images' # directory to save images\nLABEL_DIR = '/kaggle/labels' # directory to save labels","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:20:39.416843Z","iopub.execute_input":"2022-04-15T13:20:39.417170Z","iopub.status.idle":"2022-04-15T13:20:39.423880Z","shell.execute_reply.started":"2022-04-15T13:20:39.417128Z","shell.execute_reply":"2022-04-15T13:20:39.422938Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## 创建目录 Create Directories","metadata":{}},{"cell_type":"code","source":"!mkdir -p {IMAGE_DIR}\n!mkdir -p {LABEL_DIR}","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:20:40.261268Z","iopub.execute_input":"2022-04-15T13:20:40.261909Z","iopub.status.idle":"2022-04-15T13:20:41.768979Z","shell.execute_reply.started":"2022-04-15T13:20:40.261861Z","shell.execute_reply":"2022-04-15T13:20:41.767916Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Train Data\ndf = pd.read_csv(f'{ROOT_DIR}/train.csv')\ndf['old_image_path'] = f'{ROOT_DIR}/train_images/video_'+df.video_id.astype(str)+'/'+df.video_frame.astype(str)+'.jpg'\ndf['image_path']  = f'{IMAGE_DIR}/'+df.image_id+'.jpg'\ndf['label_path']  = f'{LABEL_DIR}/'+df.image_id+'.txt'\ndf['annotations'] = df['annotations'].progress_apply(eval)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:22:11.497197Z","iopub.execute_input":"2022-04-15T13:22:11.497470Z","iopub.status.idle":"2022-04-15T13:22:12.097663Z","shell.execute_reply.started":"2022-04-15T13:22:11.497441Z","shell.execute_reply":"2022-04-15T13:22:12.096746Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(df.old_image_path[1])\nprint(df.image_path[1])\nprint(df.label_path[1])","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:22:12.099748Z","iopub.execute_input":"2022-04-15T13:22:12.100083Z","iopub.status.idle":"2022-04-15T13:22:12.106691Z","shell.execute_reply.started":"2022-04-15T13:22:12.100040Z","shell.execute_reply":"2022-04-15T13:22:12.105814Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## 检查bbox数量 Number of BBoxes","metadata":{}},{"cell_type":"code","source":"df['num_bbox'] = df['annotations'].progress_apply(lambda x: len(x))\ndata = (df.num_bbox>0).value_counts(normalize=True)*100\nprint(f\"No BBox: {data[0]:0.2f}% | With BBox: {data[1]:0.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:22:13.231643Z","iopub.execute_input":"2022-04-15T13:22:13.231937Z","iopub.status.idle":"2022-04-15T13:22:13.334165Z","shell.execute_reply.started":"2022-04-15T13:22:13.231906Z","shell.execute_reply":"2022-04-15T13:22:13.333181Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"if REMOVE_NOBBOX:\n    df = df.query(\"num_bbox>0\")","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:22:26.209609Z","iopub.execute_input":"2022-04-15T13:22:26.209899Z","iopub.status.idle":"2022-04-15T13:22:26.226600Z","shell.execute_reply.started":"2022-04-15T13:22:26.209868Z","shell.execute_reply":"2022-04-15T13:22:26.225746Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# 写入图片 Write Images\n* 将图片保存到 `/kaggle/working`  copy the Images to Current Directory `/kaggle/working` \n","metadata":{}},{"cell_type":"code","source":"def make_copy(row):\n    shutil.copyfile(row.old_image_path, row.image_path)\n    return","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:23:48.875236Z","iopub.execute_input":"2022-04-15T13:23:48.875537Z","iopub.status.idle":"2022-04-15T13:23:48.880691Z","shell.execute_reply.started":"2022-04-15T13:23:48.875505Z","shell.execute_reply":"2022-04-15T13:23:48.879852Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"image_paths = df.old_image_path.tolist()\n_ = Parallel(n_jobs=-1, backend='threading')(delayed(make_copy)(row) for _, row in tqdm(df.iterrows(), total=len(df)))","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:23:49.061306Z","iopub.execute_input":"2022-04-15T13:23:49.061554Z","iopub.status.idle":"2022-04-15T13:24:13.150560Z","shell.execute_reply.started":"2022-04-15T13:23:49.061527Z","shell.execute_reply":"2022-04-15T13:24:13.148912Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## 制作数据集 Make the dataset","metadata":{}},{"cell_type":"code","source":"# check https://github.com/awsaf49/bbox for source code of following utility functions\nfrom bbox.utils import coco2yolo, coco2voc, voc2yolo\nfrom bbox.utils import draw_bboxes, load_image\nfrom bbox.utils import clip_bbox, str2annot, annot2str\n\ndef get_bbox(annots):\n    bboxes = [list(annot.values()) for annot in annots]\n    return bboxes\n\ndef get_imgsize(row):\n    row['width'], row['height'] = imagesize.get(row['image_path'])\n    return row\n\nnp.random.seed(32)\ncolors = [(np.random.randint(255), np.random.randint(255), np.random.randint(255))\\\n          for idx in range(1)]","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-04-15T13:25:14.921603Z","iopub.execute_input":"2022-04-15T13:25:14.922015Z","iopub.status.idle":"2022-04-15T13:25:15.745373Z","shell.execute_reply.started":"2022-04-15T13:25:14.921952Z","shell.execute_reply":"2022-04-15T13:25:15.744777Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"df['bboxes'] = df.annotations.progress_apply(get_bbox)\ndf.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:25:15.746950Z","iopub.execute_input":"2022-04-15T13:25:15.747402Z","iopub.status.idle":"2022-04-15T13:25:15.835562Z","shell.execute_reply.started":"2022-04-15T13:25:15.747359Z","shell.execute_reply":"2022-04-15T13:25:15.834667Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## 图片尺寸 Image-Size\n* 尺寸为 `[1280, 720]` The size is `[1280, 720]`","metadata":{}},{"cell_type":"code","source":"df['width']  = 1280\ndf['height'] = 720\ndisplay(df.head(2))","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:26:24.993774Z","iopub.execute_input":"2022-04-15T13:26:24.994594Z","iopub.status.idle":"2022-04-15T13:26:25.016010Z","shell.execute_reply.started":"2022-04-15T13:26:24.994542Z","shell.execute_reply":"2022-04-15T13:26:25.015358Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# 创建标签 Create Labels\n将标签保存为 **YOLO** 格式  \nExport labels to **YOLO** format.\n\n* 一行为一个目标 One row per object\n* 每一行的格式 Each row is class `[x_center, y_center, width, height]` format.\n* 数据归一化 Data normalized\n* 类的数字从 0 开始 Class numbers are **zero-indexed**.","metadata":{}},{"cell_type":"code","source":"cnt = 0\nall_bboxes = []\nbboxes_info = []\nfor row_idx in tqdm(range(df.shape[0])):\n    row = df.iloc[row_idx]\n    image_height = row.height\n    image_width  = row.width\n    bboxes_coco  = np.array(row.bboxes).astype(np.float32).copy()\n    num_bbox     = len(bboxes_coco)\n    names        = ['cots']*num_bbox\n    labels       = np.array([0]*num_bbox)[..., None].astype(str)\n    ## Create Annotation(YOLO)\n    with open(row.label_path, 'w') as f:\n        if num_bbox<1:\n            annot = ''\n            f.write(annot)\n            cnt+=1\n            continue\n        bboxes_voc  = coco2voc(bboxes_coco, image_height, image_width)\n        bboxes_voc  = clip_bbox(bboxes_voc, image_height, image_width)\n        bboxes_yolo = voc2yolo(bboxes_voc, image_height, image_width).astype(str)\n        all_bboxes.extend(bboxes_yolo.astype(float))\n        bboxes_info.extend([[row.image_id, row.video_id, row.sequence]]*len(bboxes_yolo))\n        annots = np.concatenate([labels, bboxes_yolo], axis=1)\n        string = annot2str(annots)\n        f.write(string)\nprint('Missing:',cnt)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-04-15T13:30:02.979049Z","iopub.execute_input":"2022-04-15T13:30:02.979474Z","iopub.status.idle":"2022-04-15T13:30:08.249484Z","shell.execute_reply.started":"2022-04-15T13:30:02.979440Z","shell.execute_reply":"2022-04-15T13:30:08.248764Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# 创建folds Create Folds\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GroupKFold\nkf = GroupKFold(n_splits = 3)\ndf = df.reset_index(drop=True)\ndf['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(kf.split(df, groups=df.video_id.tolist())):\n    df.loc[val_idx, 'fold'] = fold\ndisplay(df.fold.value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:32:57.455758Z","iopub.execute_input":"2022-04-15T13:32:57.457014Z","iopub.status.idle":"2022-04-15T13:32:58.257570Z","shell.execute_reply.started":"2022-04-15T13:32:57.456965Z","shell.execute_reply":"2022-04-15T13:32:58.256850Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# 数据集展示 Visualization","metadata":{}},{"cell_type":"code","source":"df2 = df[(df.num_bbox>0)].sample(100) # takes samples with bbox\ny = 2; x = 2\nplt.figure(figsize=(12.8*x, 7.2*y))\nfor idx in range(x*y):\n    row = df2.iloc[idx]\n    img           = load_image(row.image_path)\n    image_height  = row.height\n    image_width   = row.width\n    with open(row.label_path) as f:\n        annot = str2annot(f.read())\n    bboxes_yolo = annot[...,1:]\n    labels      = annot[..., 0].astype(int).tolist()\n    names         = ['cots']*len(bboxes_yolo)\n    plt.subplot(y, x, idx+1)\n    plt.imshow(draw_bboxes(img = img,\n                           bboxes = bboxes_yolo, \n                           classes = names,\n                           class_ids = labels,\n                           class_name = True, \n                           colors = colors, \n                           bbox_format = 'yolo',\n                           line_thickness = 2))\n    plt.axis('OFF')\nplt.tight_layout()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-15T13:34:36.972962Z","iopub.execute_input":"2022-04-15T13:34:36.973306Z","iopub.status.idle":"2022-04-15T13:34:39.094912Z","shell.execute_reply.started":"2022-04-15T13:34:36.973271Z","shell.execute_reply":"2022-04-15T13:34:39.093890Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# 制作数据集 Make Dataset","metadata":{}},{"cell_type":"code","source":"train_files = []\nval_files   = []\ntrain_df = df.query(\"fold!=@FOLD\")\nvalid_df = df.query(\"fold==@FOLD\")\ntrain_files += list(train_df.image_path.unique())\nval_files += list(valid_df.image_path.unique())\nlen(train_files), len(val_files)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:34:58.412978Z","iopub.execute_input":"2022-04-15T13:34:58.413269Z","iopub.status.idle":"2022-04-15T13:34:58.432452Z","shell.execute_reply.started":"2022-04-15T13:34:58.413238Z","shell.execute_reply":"2022-04-15T13:34:58.431803Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# 训练配置 Configuration","metadata":{}},{"cell_type":"code","source":"import yaml\n\ncwd = '/kaggle/working/'\n\nwith open(os.path.join( cwd , 'train.txt'), 'w') as f:\n    for path in train_df.image_path.tolist():\n        f.write(path+'\\n')\n            \nwith open(os.path.join(cwd , 'val.txt'), 'w') as f:\n    for path in valid_df.image_path.tolist():\n        f.write(path+'\\n')\n\ndata = dict(\n    path  = '/kaggle/working',\n    train =  os.path.join( cwd , 'train.txt') ,\n    val   =  os.path.join( cwd , 'val.txt' ),\n    nc    = 1,\n    names = ['cots'],\n    )\n\nwith open(os.path.join( cwd , 'gbr.yaml'), 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False)\n\nf = open(os.path.join( cwd , 'gbr.yaml'), 'r')\nprint('\\nyaml:')\nprint(f.read())","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-15T13:44:55.442514Z","iopub.execute_input":"2022-04-15T13:44:55.442910Z","iopub.status.idle":"2022-04-15T13:44:55.459476Z","shell.execute_reply.started":"2022-04-15T13:44:55.442868Z","shell.execute_reply":"2022-04-15T13:44:55.458877Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## 训练参数 Parameters","metadata":{}},{"cell_type":"code","source":"%%writefile /kaggle/working/hyp.yaml\nlr0: 0.01  # 学习率 initial learning rate (SGD=1E-2, Adam=1E-3)\nlrf: 0.1  # 最终学习率 final OneCycleLR learning rate (lr0 * lrf)\nmomentum: 0.937  # SGD动量 SGD momentum/Adam beta1\nweight_decay: 0.0005  # 优化器权重衰减 optimizer weight decay 5e-4\nwarmup_epochs: 3.0  # 热启动 warmup epochs\nwarmup_momentum: 0.8  # 热启动初始动量 warmup initial momentum\nwarmup_bias_lr: 0.1  # 热启动初始偏差lr warmup initial bias lr\nbox: 0.05  # box损失增益 box loss gain\ncls: 0.5  # cls损失增益 cls loss gain\ncls_pw: 1.0  # cls BCELoss positive_weight\nobj: 1.0  # obj loss gain (scale with pixels)\nobj_pw: 1.0  # obj BCELoss positive_weight\niou_t: 0.20  # IoU training threshold\nanchor_t: 4.0  # anchor-multiple threshold\n# anchors: 3  # anchors per output layer (0 to ignore)\nfl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\nhsv_h: 0.015  # 图像 HSV-Hue 增强 image HSV-Hue augmentation (fraction)\nhsv_s: 0.7  # 图像 HSV 饱和度增强 image HSV-Saturation augmentation (fraction)\nhsv_v: 0.4  # 图像 HSV 值增强 image HSV-Value augmentation (fraction)\ndegrees: 0.0  # 图像旋转 image rotation (+/- deg)\ntranslate: 0.10  # 平移 translate\nscale: 0.5  # 缩放 scale\nshear: 0.0  # 左右偏移 shear\nperspective: 0.0  # 图像透视 image perspective\nflipud: 0.5  # 上下翻转 Flip upside down(probability)\nfliplr: 0.5  # 左右翻转 Flip left and right(probability)\nmosaic: 0.5  # 马赛克 mosaic(probability)\nmixup: 0.5   # mixup (probability)\ncopy_paste: 0.0  # 复制粘贴 segment copy-paste (probability)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-15T14:07:37.235910Z","iopub.execute_input":"2022-04-15T14:07:37.236315Z","iopub.status.idle":"2022-04-15T14:07:37.246817Z","shell.execute_reply.started":"2022-04-15T14:07:37.236274Z","shell.execute_reply":"2022-04-15T14:07:37.245875Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working\n!rm -r /kaggle/working/yolov5\n# !git clone https://github.com/ultralytics/yolov5\n!cp -r /kaggle/input/yolov5-lib-ds /kaggle/working/yolov5\n%cd yolov5\n%pip install -qr requirements.txt  # install\n\nfrom yolov5 import utils\ndisplay = utils.notebook_init()  # check","metadata":{"execution":{"iopub.status.busy":"2022-04-15T13:45:08.701316Z","iopub.execute_input":"2022-04-15T13:45:08.701646Z","iopub.status.idle":"2022-04-15T13:45:24.512897Z","shell.execute_reply.started":"2022-04-15T13:45:08.701611Z","shell.execute_reply":"2022-04-15T13:45:24.511564Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# 训练 Training","metadata":{}},{"cell_type":"code","source":"!python train.py --img {DIM}\\\n--batch {BATCH}\\\n--epochs {EPOCHS}\\\n--optimizer {OPTMIZER}\\\n--data /kaggle/working/gbr.yaml\\\n--hyp /kaggle/working/hyp.yaml\\\n--weights {MODEL}.pt\\\n--project {PROJECT} --name {NAME}\\\n--exist-ok","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-27T12:08:31.728605Z","iopub.execute_input":"2022-02-27T12:08:31.729175Z","iopub.status.idle":"2022-02-27T12:12:39.982821Z","shell.execute_reply.started":"2022-02-27T12:08:31.72913Z","shell.execute_reply":"2022-02-27T12:12:39.981946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 查看结果 Overview\n<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\"><a href=\"https://wandb.ai/awsaf49/great-barrier-reef-public\">点击在此网站查看训练结果 View the Complete Dashboard Here</a></span>\n","metadata":{}},{"cell_type":"code","source":"OUTPUT_DIR = '{}/{}'.format(PROJECT, NAME)\n!ls {OUTPUT_DIR}","metadata":{"execution":{"iopub.status.busy":"2022-02-27T12:12:39.984465Z","iopub.execute_input":"2022-02-27T12:12:39.984783Z","iopub.status.idle":"2022-02-27T12:12:40.65784Z","shell.execute_reply.started":"2022-02-27T12:12:39.984715Z","shell.execute_reply":"2022-02-27T12:12:40.656985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -r {IMAGE_DIR}\n!rm -r {LABEL_DIR}","metadata":{"execution":{"iopub.status.busy":"2022-02-27T12:12:42.894126Z","iopub.status.idle":"2022-02-27T12:12:42.894512Z","shell.execute_reply.started":"2022-02-27T12:12:42.894295Z","shell.execute_reply":"2022-02-27T12:12:42.894314Z"},"trusted":true},"execution_count":null,"outputs":[]}]}